{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime= pd.read_csv('C:/Users/shrad/Desktop/pro/chicago.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.head()\n",
    "# 23 columns "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['Date', 'Block', 'Primary Type', 'District','Location', 'Arrest','Year']\n",
    "x = crime[feature_cols] # Features\n",
    "y = crime.District # Target variable\n",
    "c=x.iloc[0:,2]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=crime)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dispaying date in the format of month, day, year, hour, minutes, seconds\n",
    "df['Date'] =  pd.to_datetime(df['Date'], format = '%m/%d/%Y %H:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import *\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(df['Date'].apply(lambda d: d.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering: First it was important toprocess the “Date” feature into a form suitable for writing python code. After this processing, we feature engineered [16]\n",
    "#the separate features of “Month”, “Day” and “Hour”, since the “Date” feature in our original dataset was a combination of the month of the crime, the day of the crime and the time\n",
    "#of the crime. This was achieved by using the apply() function of the pandas package and python’s datetime module\n",
    "\n",
    "df['Month'] = df['Date'].apply(lambda r:r.month)\n",
    "df['Day'] = df['Date'].apply(lambda d:d.day)\n",
    "df['Hour'] = df['Date'].apply(lambda r:r.hour)\n",
    "min(df['Hour'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compressing the dataset: The dataset was then compressed and reshaped into a new dataset. This new dataset has been named as crimeDat in all further discussions in this\n",
    "#work. crimeDat was the final dataset that was used in our work. Following is the pseudocode for creating crimeDat. In the code, data is our dataset before compression and reshaping.\n",
    "import pandas as pd\n",
    "cols=['Month','Day','District','Hour']\n",
    "crimedat = pd.DataFrame(columns= cols)\n",
    "print(crimedat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmon = df.loc[df['Month'] == 1]\n",
    "dfmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Following is the pseudocode for creating crimeDat.\n",
    "#for every month, day, hour and district the crime count is displayed \n",
    "# At this point , crimedat has 138384 rows x 5 columns]\n",
    "import pandas as pd\n",
    "cols=['Month','Day','Hour','District','crimecount']\n",
    "crimedat = pd.DataFrame(columns= cols)\n",
    "print(crimedat)\n",
    "for i in range(1,13):\n",
    "    dfmon = df.loc[df['Month'] == i]\n",
    "    for j in range(1,32):\n",
    "        dfday = dfmon.loc[dfmon['Day']==j]\n",
    "        for k in range(1, 13):\n",
    "            dfhour = dfday.loc[dfday['Hour']==k]\n",
    "            for d in range(1,32):\n",
    "                dfdis = dfhour.loc[dfhour['District']==d]\n",
    "                nocr= dfdis.shape[0]\n",
    "                crimedat = crimedat.append({'Month':i, 'Day': j, 'Hour': k, 'District': d, 'crimecount':nocr}, ignore_index=True)\n",
    "            \n",
    "\n",
    "print(crimedat)\n",
    "       \n",
    "             \n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of rows where crime count is zero, the dataset is reduced to 96600 rows × 5 columns\n",
    "indexlist=[]\n",
    "for i in range(0,138384):\n",
    "    if crimedat['crimecount'][i]==0:\n",
    "            indexlist.append(i)\n",
    "            \n",
    "crimedat.drop(indexlist, inplace = True)\n",
    "crimedat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying all indices where crimecount is zero\n",
    "print(indexlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserting a column 'alarm'.\n",
    "#A new target feature crimeDat[Alarm] was then engineered for the crimeDat dataset . The target feature had the values 0, 1 or 2 based on the alarm rate of a particular entry.\n",
    "crimedat.insert(5,'Alarm','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.iloc[[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.head()\n",
    "print(crimedat['crimecount'])\n",
    "type(crimedat['crimecount'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.info()\n",
    "crimedat['crimecount'] = pd.to_numeric(crimedat['crimecount'])\n",
    "print(\"after\" )\n",
    "crimedat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.info()\n",
    "crimedat['Hour'] = pd.to_numeric(crimedat['Hour'])\n",
    "print(\"after\" )\n",
    "crimedat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.info()\n",
    "crimedat['Month'] = pd.to_numeric(crimedat['Month'])\n",
    "print(\"after\" )\n",
    "crimedat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.info()\n",
    "crimedat['Day'] = pd.to_numeric(crimedat['Day'])\n",
    "print(\"after\" )\n",
    "crimedat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.info()\n",
    "crimedat['District'] = pd.to_numeric(crimedat['District'])\n",
    "print(\"after\" )\n",
    "crimedat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.info()\n",
    "crimedat['Alarm'] = pd.to_numeric(crimedat['Alarm'])\n",
    "print(\"after\" )\n",
    "crimedat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z= crimedat['crimecount'].to_numpy()\n",
    "print(z[15])\n",
    "type(z[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crimedat['Alarm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelling a particular entry as 0(Low alarm), 1(Medium alarm) or 2(High alarm) is a process that would be subjectively different from approach to approach.\n",
    "#The following pseudocode describes how the target labels are set.\n",
    "num =138384\n",
    "for u in range(0,num):\n",
    "    if u not in indexlist:\n",
    "        x= crimedat['crimecount'][u]\n",
    "        y= crimedat['Alarm'][u]\n",
    "        if (x <= 14):\n",
    "            print(u)\n",
    "            print('x is',x)\n",
    "            y =0\n",
    "        elif ((x >=15) and (x <=33)):\n",
    "            y =1\n",
    "        else:\n",
    "            y =2\n",
    "        crimedat['Alarm'][u] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crimedat.iloc[:200])\n",
    "print(crimedat['crimecount'][50])\n",
    "print(crimedat['Alarm'][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(crimedat['crimecount'][9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat['Month'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows the distribution of the values in crimeDat[CrimeCount]. The distribution bears a close resemblance to the normal distribution.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(crimedat['crimecount'], bins=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#describes the correlation matrix between the features in crimeDat and the following conclusions can be drawn of it :\n",
    "#Almost all the features have no correlation with each other. This is good as certain machine learning algorithms are affected adversely by multi-collinearity.\n",
    "#The feature Hour and crimecount has the greatest positive correlation with the target feature Alarm.\n",
    "dis = crimedat.corr(method='pearson')\n",
    "print(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (5,5))\n",
    "\n",
    "sns.heatmap(dis, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2 =['Month','Day','District','Hour','crimecount']\n",
    "print(crimedat[cols2])\n",
    "y = crimedat['Alarm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(crimedat.drop([\"Alarm\"],1))\n",
    "print(\"Shape of X:\",X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(crimedat[\"Alarm\"])\n",
    "print(\"Shape of y:\",y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(\"Enter the splitting factor (i.e) ratio between train and test\")\n",
    "s_f = float(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = math.floor(s_f * X.shape[0])\n",
    "n_test = math.ceil((1-s_f) * X.shape[0])\n",
    "X_traing = X[:n_train]\n",
    "y_traing = y[:n_train]\n",
    "X_testg = X[n_train:]\n",
    "y_testg = y[n_train:]\n",
    "print(\"Total  training samples for independent :\",X_traing.shape[0])\n",
    "print(\"Total testing samples for independent:\",X_testg.shape[0])\n",
    "print(\"total number of training samples for dependent \", y_traing.shape[0])\n",
    "print(\"total number of testing samples for dependent\", y_testg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifier object\n",
    "dtree4 = DecisionTreeClassifier(criterion='gini', splitter='random', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "# Train Decision Tree Classifier\n",
    "dtree4.fit(X_traing,y_traing)\n",
    "#Predict the response for test dataset\n",
    "y_predd = dtree4.predict(X_testg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of model\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_testg,y_predd))\n",
    "print(confusion_matrix(y_testg, y_predd))\n",
    "print(\" The accuracy obtained using Decision tree classifier is {0:.8f}%\".format(100*(dtree4.score(X_testg, y_testg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(crimedat[cols2], y, test_size=0.25) # 70% training and 25% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifier object\n",
    "dtree = DecisionTreeClassifier(criterion='gini', splitter='random', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "# Train Decision Tree Classifier\n",
    "dtree.fit(x_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = dtree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of model\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\" The accuracy obtained using Decision tree classifier is {0:.8f}%\".format(100*(dtree.score(x_test, y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)*100)\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred,average='macro')*100)\n",
    "print(\"f1 score:\", metrics.f1_score(y_test,y_pred, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 =train_test_split(crimedat[cols2],y, test_size=0.25,  random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors=5\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(x_train1, y_train1)\n",
    "y_pred1= neigh.predict(x_test1)\n",
    "acc= metrics.accuracy_score(y_test1,y_pred1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test1, y_pred1)*100)\n",
    "print(\"Precision:\",metrics.precision_score(y_test1, y_pred1, average='macro')*100)\n",
    "print(\"Recall:\",metrics.recall_score(y_test1, y_pred1,average='macro')*100)\n",
    "print(\"f1 score:\", metrics.f1_score(y_test1,y_pred1, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "    neigh.fit(x_train1, y_train1)\n",
    "    y_pred1= neigh.predict(x_test1)\n",
    "    error.append(np.mean(y_pred != y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 =train_test_split(crimedat[cols2],y, test_size=0.33,  random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "svm1 = svm.SVC(kernel='rbf') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm1.fit(x_train2, y_train2)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred2 = svm1.predict(x_test2)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2)*100)\n",
    "print(\"Precision:\",metrics.precision_score(y_test2, y_pred2, average='macro')*100)\n",
    "print(\"Recall:\",metrics.recall_score(y_test2, y_pred2,average='macro')*100)\n",
    "print(\"f1 score:\", metrics.f1_score(y_test2,y_pred2, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3, x_test3, y_train3, y_test3 =train_test_split(crimedat[cols2],y, test_size=0.25,  random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(x_train3,y_train3)\n",
    "\n",
    "#\n",
    "y_pred3=logreg.predict(x_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test3, y_pred3)*100)\n",
    "print(\"Precision:\",metrics.precision_score(y_test3, y_pred3, average='macro')*100)\n",
    "print(\"Recall:\",metrics.recall_score(y_test3, y_pred3,average='macro')*100)\n",
    "print(\"f1 score:\", metrics.f1_score(y_test3,y_pred3, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train4, x_test4, y_train4, y_test4 =train_test_split(crimedat[cols2],y, test_size=0.25,  random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(x_train4, y_train4)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred4 = gnb.predict(x_test4)\n",
    "y_pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test4, y_pred4)*100)\n",
    "print(\"Precision:\",metrics.precision_score(y_test4, y_pred4, average='macro')*100)\n",
    "print(\"Recall:\",metrics.recall_score(y_test4, y_pred4,average='macro')*100)\n",
    "print(\"f1 score:\", metrics.f1_score(y_test4,y_pred4, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train5, x_test5, y_train5, y_test5 =train_test_split(crimedat[cols2],y, test_size=0.25,  random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "ran=RandomForestClassifier(n_estimators=28,criterion='gini', max_depth=2, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=False, verbose=0, warm_start=False, class_weight=\"balanced\", ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "ran.fit(x_train5,y_train5)\n",
    "\n",
    "y_pred5=ran.predict(x_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test5, y_pred5)*100)\n",
    "print(\"Precision:\",metrics.precision_score(y_test5, y_pred5, average='macro')*100)\n",
    "print(\"Recall:\",metrics.recall_score(y_test5, y_pred5,average='macro')*100)\n",
    "print(\"f1 score:\", metrics.f1_score(y_test5,y_pred5, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedat['Alarm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train6, x_test6, y_train6, y_test6 =train_test_split(crimedat[cols2],y, test_size=0.20,  random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_booster = GradientBoostingClassifier(learning_rate=1.0)\n",
    "gradient_booster.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=500, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features='sqrt', verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0).fit(x_train6, y_train6)\n",
    "clf.score(x_test6, y_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_booster.fit(x_train6,y_train6)\n",
    "print(classification_report(y_test6,gradient_booster.predict(x_test6)))\n",
    "y_pred6= gradient_booster.predict(x_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test6, y_pred6)*100)\n",
    "print(\"Precision:\",metrics.precision_score(y_test6, y_pred6, average='macro')*100)\n",
    "print(\"Recall:\",metrics.recall_score(y_test6, y_pred6,average='macro')*100)\n",
    "print(\"f1 score:\", metrics.f1_score(y_test6,y_pred6, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
